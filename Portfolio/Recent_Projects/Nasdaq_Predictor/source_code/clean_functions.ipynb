{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'boto3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3d55fde2bc2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0menviron\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SNS_ARN'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'arn:aws:sns:us-west-2:585222384446:GroupProject'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'boto3'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "from math import floor\n",
    "import warnings\n",
    "import csv\n",
    "import io\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#import boto3\n",
    "from os import environ as env\n",
    "env['SNS_ARN'] = 'arn:aws:sns:us-west-2:585222384446:GroupProject'\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allow S3 in AWS to read our files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_s3_file(bucket, file_key):\n",
    "    s3 = boto3.client('s3')\n",
    "    csvfile = s3.get_object(Bucket=bucket, Key=file_key)\n",
    "    df = pd.read_csv(io.BytesIO(csvfile['Body'].read()), encoding='utf8')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(df):\n",
    "    nasdaq = df\n",
    "    nasdaq_2 = nasdaq[nasdaq['Close']!= 'Close']\n",
    "    nasdaq_2['Close2'] = nasdaq_2['Close'].astype(float)\n",
    "    nasdaq_2.drop(columns=['Open', 'High', 'Low', 'Volume', 'Close'], inplace=True)\n",
    "    nasdaq_2.set_index(['Symbol', 'Date'], inplace =True)\n",
    "    nasdaq_2 = nasdaq_2.groupby('Symbol').pct_change()\n",
    "    nasdaq_2 = nasdaq_2.dropna()\n",
    "    nasdaq_2 = nasdaq_2.rename(columns={'Close2': 'Returns'})\n",
    "    nasdaq_2 = nasdaq_2.sort_values('Date')\n",
    "    return nasdaq_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Trading Signals / Moving Averages / Bollinger Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trading_signals(nasdaq_2, short_window=1, long_window=10, short_vol_window=1, long_vol_window=10, bollinger_window=20):\n",
    "\n",
    "    # Construct a `Fast` and `Slow` Exponential Moving Average from short and long windows, respectively\n",
    "    nasdaq_2['fast_close'] = nasdaq_2['Returns'].ewm(halflife=short_window).mean()\n",
    "    nasdaq_2['slow_close'] = nasdaq_2['Returns'].ewm(halflife=long_window).mean()\n",
    "\n",
    "    # Construct a crossover trading signal\n",
    "    nasdaq_2['crossover_long'] = np.where(nasdaq_2['fast_close'] > nasdaq_2['slow_close'], 1.0, 0.0)\n",
    "    nasdaq_2['crossover_short'] = np.where(nasdaq_2['fast_close'] < nasdaq_2['slow_close'], -1.0, 0.0)\n",
    "    nasdaq_2['crossover_signal'] = nasdaq_2['crossover_long'] + nasdaq_2['crossover_short']\n",
    "\n",
    "    # Construct a `Fast` and `Slow` Exponential Moving Average from short and long windows, respectively\n",
    "    nasdaq_2['fast_vol'] = nasdaq_2['Returns'].ewm(halflife=short_vol_window).std()\n",
    "    nasdaq_2['slow_vol'] = nasdaq_2['Returns'].ewm(halflife=long_vol_window).std()\n",
    "\n",
    "    # Construct a crossover trading signal\n",
    "    nasdaq_2['vol_trend_long'] = np.where(nasdaq_2['fast_vol'] < nasdaq_2['slow_vol'], 1.0, 0.0)\n",
    "    nasdaq_2['vol_trend_short'] = np.where(nasdaq_2['fast_vol'] > nasdaq_2['slow_vol'], -1.0, 0.0) \n",
    "    nasdaq_2['vol_trend_signal'] = nasdaq_2['vol_trend_long'] + nasdaq_2['vol_trend_short']\n",
    "    \n",
    "    # Calculate rolling mean and standard deviation\n",
    "    nasdaq_2['bollinger_mid_band'] = nasdaq_2['Returns'].rolling(window=bollinger_window).mean()\n",
    "    nasdaq_2['bollinger_std'] = nasdaq_2['Returns'].rolling(window=20).std()\n",
    "\n",
    "    # Calculate upper and lowers bands of bollinger band\n",
    "    nasdaq_2['bollinger_upper_band']  = nasdaq_2['bollinger_mid_band'] + (nasdaq_2['bollinger_std'] * 1)\n",
    "    nasdaq_2['bollinger_lower_band']  = nasdaq_2['bollinger_mid_band'] - (nasdaq_2['bollinger_std'] * 1)\n",
    "\n",
    "    # Calculate bollinger band trading signal\n",
    "    nasdaq_2['bollinger_long'] = np.where(nasdaq_2['Returns'] < nasdaq_2['bollinger_lower_band'], 1.0, 0.0)\n",
    "    nasdaq_2['bollinger_short'] = np.where(nasdaq_2['Returns'] > nasdaq_2['bollinger_upper_band'], -1.0, 0.0)\n",
    "    nasdaq_2['bollinger_signal'] = nasdaq_2['bollinger_long'] + nasdaq_2['bollinger_short']\n",
    "    \n",
    "    # Set x variable list of features\n",
    "    x_var_list = ['crossover_signal', 'vol_trend_signal', 'bollinger_signal']\n",
    "\n",
    "    # Shift DataFrame values by 1\n",
    "    nasdaq_2[x_var_list] = nasdaq_2[x_var_list].shift(1)\n",
    "\n",
    "    # Drop NAs and replace positive/negative infinity values\n",
    "    nasdaq_2.dropna(subset=x_var_list, inplace=True)\n",
    "    nasdaq_2.dropna(subset=['Returns'], inplace=True)\n",
    "    nasdaq_2 = nasdaq_2.replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # Construct the dependent variable where if daily return is greater than 0, then 1, else, 0.\n",
    "    # Changing the target variable away from 0 introduces the problem of an imbalanced dataset\n",
    "    nasdaq_2.dropna(inplace=True)\n",
    "    \n",
    "    return nasdaq_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Target List to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_list(nasdaq_2):\n",
    "\n",
    "    nasdaq_3 = nasdaq_2.copy()\n",
    "   \n",
    "    # Creating a target list\n",
    "    target_list = []\n",
    "    stoprw = len(nasdaq_3)\n",
    "    for rw in range(stoprw):\n",
    "        if rw != stoprw:\n",
    "            rwn = rw  \n",
    "            if nasdaq_3['Returns'][rwn]> 0.4:\n",
    "                target_list.append(1)\n",
    "            else:\n",
    "                target_list.append(0)\n",
    "        else: \n",
    "            print(\"hit!\")\n",
    "            target_list.append(0)\n",
    "    nasdaq_3['Target'] = target_list\n",
    "    return nasdaq_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(df):\n",
    "    \n",
    "    #Create DF with Returns\n",
    "    nas = df.drop(['Returns'], axis=1)\n",
    "    nv = ['fast_close', 'slow_close', 'fast_vol','slow_vol', 'bollinger_mid_band', 'bollinger_std', 'bollinger_upper_band']\n",
    "    stdrd = nas[nv]\n",
    "    \n",
    "    #standardizing using min max scaler\n",
    "    minmax = preprocessing.MinMaxScaler()\n",
    "    x_unstdrd = stdrd.values\n",
    "    x_stdrd = minmax.fit_transform(x_unstdrd)\n",
    "    nas[nv] = x_stdrd\n",
    "    return nas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, cutoff):\n",
    "    cut = floor(len(df) * cutoff)\n",
    "    train_df = df[:cut]\n",
    "    test_df = df[cut:]\n",
    "    print(f\"train_df: {len(train_df)}\")\n",
    "    print(f\"test_df: {len(test_df)}\")\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(train,test):\n",
    "    \n",
    "    # Construct the X_train and y_train datasets\n",
    "    X_train = train.drop(['Target'], axis=1)\n",
    "    y_train = train['Target']\n",
    "    # Constructing X_test and y_test\n",
    "    X_test = test.drop(['Target'], axis=1)\n",
    "    y_test = test['Target']\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make a prediction of \"y\" values from the X_test dataset\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Assemble actual y data (Y_test) with predicted y data (from just above) into two columns in a dataframe:\n",
    "    Results = y_test.to_frame()\n",
    "    Results[\"Predicted Value\"] = predictions\n",
    "    Results = Results[Results['Predicted Value']>0]\n",
    "    Results_final = Results.groupby('Symbol').first()\n",
    "    return Results_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Email and Send Tickers that are predicted to jump by 40% the next day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_message(df):\n",
    "    big_str = \"\"\"These are today's buys: \\n\"\"\"\n",
    "    for index, row in df.iterrows():\n",
    "        big_str += str(index) + \": \" + str(row['Predicted Value']) + \"\\n\"\n",
    "    return big_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the Email and Send Message to recipients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_message_sns(message):\n",
    "    \"\"\"\n",
    "    :param message: str: message to be sent to SNS\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    sns_arn = env.get('SNS_ARN').strip()\n",
    "    sns_client = boto3.client('sns')\n",
    "    try:\n",
    "        response = sns_client.publish(\n",
    "            TopicArn=sns_arn,\n",
    "            Message=message\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR PUBLISHING MESSAGE TO SNS: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function called Handler that calls all functions and returns the Message in Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handler(event, context):\n",
    "    # This is where all the other functions are called. \n",
    "    df = read_s3_file('project2-lambda','final-model-data.csv')\n",
    "    df = fetch_data(df)\n",
    "    trading_signals_df = trading_signals(df)\n",
    "    target_list_df = target_list(trading_signals_df)\n",
    "    standardize_df = standardize(target_list_df)\n",
    "    train,test = train_test_split(standardize_df,.7)\n",
    "    model_df = model(train, test)\n",
    "    message = create_message(model_df)\n",
    "    publish_message_sns(message)\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: 660089\n",
      "test_df: 282896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"These are today's buys: \\nABEO: 1\\nABUS: 1\\nACAD: 1\\nADAP: 1\\nADILW: 1\\nAEY: 1\\nAEZS: 1\\nAGBAR: 1\\nAGBAW: 1\\nAGFSW: 1\\nAGRX: 1\\nAGTC: 1\\nAHPI: 1\\nAIHS: 1\\nAIRTW: 1\\nAKER: 1\\nALACW: 1\\nALLK: 1\\nALT: 1\\nAMCIW: 1\\nAMRH: 1\\nAMRHW: 1\\nANDAR: 1\\nANDAW: 1\\nANTE: 1\\nAPEX: 1\\nAPOP: 1\\nAPOPW: 1\\nARDX: 1\\nARQL: 1\\nARTLW: 1\\nARYAW: 1\\nASFI: 1\\nASLN: 1\\nASRT: 1\\nASTC: 1\\nATHE: 1\\nAUPH: 1\\nAVCTW: 1\\nAXAS: 1\\nAYRO: 1\\nBGFV: 1\\nBHTG: 1\\nBIMI: 1\\nBIOL: 1\\nBLCM: 1\\nBLNK: 1\\nBLNKW: 1\\nBNGOW: 1\\nBNTCW: 1\\nBOLD: 1\\nBRPAR: 1\\nBRPAW: 1\\nCAPR: 1\\nCBAT: 1\\nCDEV: 1\\nCETX: 1\\nCETXP: 1\\nCETXW: 1\\nCFFAW: 1\\nCFRX: 1\\nCGIX: 1\\nCHEKW: 1\\nCHEKZ: 1\\nCIDM: 1\\nCLMT: 1\\nCLRBZ: 1\\nCLSK: 1\\nCNST: 1\\nCPSH: 1\\nCREXW: 1\\nCRSAW: 1\\nCRVS: 1\\nCTIB: 1\\nCTXRW: 1\\nCYOU: 1\\nDDMXW: 1\\nDGLY: 1\\nDKNGZ: 1\\nDLPN: 1\\nDLPNW: 1\\nDNJR: 1\\nDOGZ: 1\\nDRAD: 1\\nDRIO: 1\\nDRIOW: 1\\nDSKEW: 1\\nDTEA: 1\\nDTSS: 1\\nDUO: 1\\nDXLG: 1\\nECOR: 1\\nEDSA: 1\\nEFOI: 1\\nELOX: 1\\nELTK: 1\\nENDP: 1\\nENOB: 1\\nENT: 1\\nENTXW: 1\\nESTRW: 1\\nEVER: 1\\nEXPCW: 1\\nEYEGW: 1\\nEYES: 1\\nEYESW: 1\\nFCEL: 1\\nFLMNW: 1\\nFOSL: 1\\nFTEK: 1\\nFTSV: 1\\nFVEVV: 1\\nFWP: 1\\nGENE: 1\\nGHSI: 1\\nGMBL: 1\\nGMBLW: 1\\nGNPX: 1\\nGNUS: 1\\nGPAQW: 1\\nGRNVR: 1\\nGSMGW: 1\\nGTEC: 1\\nGURE: 1\\nHALL: 1\\nHCCHR: 1\\nHCCHW: 1\\nHEPA: 1\\nHJLIW: 1\\nHTBX: 1\\nHUGE: 1\\nICON: 1\\nIDEX: 1\\nIEAWW: 1\\nIMACW: 1\\nIMMU: 1\\nIMRN: 1\\nIMRNW: 1\\nINO: 1\\nINPX: 1\\nINWK: 1\\nISEE: 1\\nIZEA: 1\\nJAKK: 1\\nJFIN: 1\\nJFKKW: 1\\nJRJC: 1\\nKBLMR: 1\\nKBLMW: 1\\nKOD: 1\\nKTOVW: 1\\nKZR: 1\\nLACQW: 1\\nLCA: 1\\nLCAHU: 1\\nLCAHW: 1\\nLFACW: 1\\nLGHL: 1\\nLGHLW: 1\\nLIFE: 1\\nLLIT: 1\\nLMFA: 1\\nLMFAW: 1\\nLOACR: 1\\nLOACW: 1\\nLONE: 1\\nLPTH: 1\\nLPTX: 1\\nLTRPB: 1\\nMARK: 1\\nMBOT: 1\\nMBRX: 1\\nMCMJW: 1\\nMDGSW: 1\\nMESO: 1\\nMGNX: 1\\nMICT: 1\\nMIK: 1\\nMITO: 1\\nMKD: 1\\nMNCLW: 1\\nMOXC: 1\\nMRAM: 1\\nMREO: 1\\nMRSN: 1\\nMTC: 1\\nMTP: 1\\nMVIS: 1\\nNAKD: 1\\nNBACW: 1\\nNCSM: 1\\nNDRAW: 1\\nNESRW: 1\\nNETE: 1\\nNFINW: 1\\nNGHC: 1\\nNHLDW: 1\\nNKLA: 1\\nNKLAW: 1\\nNLTX: 1\\nNMRD: 1\\nNPAWW: 1\\nNUROW: 1\\nNUZE: 1\\nNVIV: 1\\nNXTC: 1\\nNYMT: 1\\nNYMTM: 1\\nNYMTN: 1\\nNYMTO: 1\\nNYMTP: 1\\nOAS: 1\\nOCGN: 1\\nOMER: 1\\nONTXW: 1\\nONVO: 1\\nOPESW: 1\\nOPGN: 1\\nORSNR: 1\\nORSNW: 1\\nOTLK: 1\\nOTLKW: 1\\nOXBRW: 1\\nPAACW: 1\\nPAVMW: 1\\nPDSB: 1\\nPETZ: 1\\nPHCF: 1\\nPHIOW: 1\\nPHUNW: 1\\nPIXY: 1\\nPOAI: 1\\nPOLA: 1\\nPSTI: 1\\nPSTV: 1\\nPSTVZ: 1\\nPT: 1\\nPTACW: 1\\nPTGX: 1\\nPTLA: 1\\nQUMU: 1\\nRAPT: 1\\nRCEL: 1\\nRKDA: 1\\nRNET: 1\\nROSE: 1\\nROSEU: 1\\nROSEW: 1\\nRTTR: 1\\nSAQNW: 1\\nSAUC: 1\\nSAVA: 1\\nSCON: 1\\nSECO: 1\\nSGBX: 1\\nSGLBW: 1\\nSHIP: 1\\nSHIPW: 1\\nSHIPZ: 1\\nSHLO: 1\\nSINO: 1\\nSKYS: 1\\nSLGL: 1\\nSLS: 1\\nSNES: 1\\nSNGXW: 1\\nSNOA: 1\\nSNOAW: 1\\nSOLO: 1\\nSOLOW: 1\\nSOLY: 1\\nSPCB: 1\\nSQBG: 1\\nSRTSW: 1\\nSUMR: 1\\nSVRA: 1\\nSXTC: 1\\nTBLT: 1\\nTBLTW: 1\\nTCON: 1\\nTDACW: 1\\nTELL: 1\\nTEUM: 1\\nTHCAW: 1\\nTHMO: 1\\nTHOR: 1\\nTKKSR: 1\\nTKKSW: 1\\nTLSA: 1\\nTMDI: 1\\nTOPS: 1\\nTOTAW: 1\\nTRCB: 1\\nTRIL: 1\\nTRVI: 1\\nTTNP: 1\\nTTPH: 1\\nTUSK: 1\\nTZACW: 1\\nUMRX: 1\\nUONE: 1\\nUSEG: 1\\nUSWS: 1\\nUSWSW: 1\\nVISL: 1\\nVIVE: 1\\nVVUS: 1\\nVXRT: 1\\nWISA: 1\\nWKHS: 1\\nWTRH: 1\\nWW: 1\\nXBIOW: 1\\nXBIT: 1\\nXELA: 1\\nXELB: 1\\nXSPA: 1\\nYGYI: 1\\nYTEN: 1\\nZGYHW: 1\\nZN: 1\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler(None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda858da8c7b8424fa984dc3fe5f9db910d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
