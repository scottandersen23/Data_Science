{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN FUNCTIONS NOTEBOOK\n",
    "### Project: CRYPTO-TRADING-SYSTEM\n",
    "### Copyright: Mantis Trading\n",
    "#### Table of Contents\n",
    "    1. Data Pre-Processing Functions\n",
    "    2. Feature Engineering Functions\n",
    "    3. XG Boost Mult-Classification Functions\n",
    "    4. Backtesting Functions (backtest, performance viz)\n",
    "    5. Live Trade Functions \n",
    "    6. Real Time Management Functions (Dash, Reporting) \n",
    "    7. Libraries\n",
    "    8. Appendix\n",
    "    \n",
    "\n",
    "##### WORK ITEMS\n",
    "    1. update test dataframe so every 6 hrs there is a row... forward fill data (team)\n",
    "    2. Re-Train Model on Sequential Data, Test on sequential Data and output predicted df for test(70/30 split)  (team)\n",
    "    3. Finish Strategy logic in backtest (grant)\n",
    "    4. Finish performance calculations and visualations code for backtest (scott)\n",
    "    5. Finish live_trader_mantis.py (team)\n",
    "        - finish initialization function\n",
    "        - finish fetch_data function\n",
    "        - finish generate_feature function\n",
    "        - finish rebalancePortfolio function\n",
    "        - add shrimpy websocket code\n",
    "        - add shrimpy execution functionality\n",
    "    6. Finish real_time_manager.py (team)\n",
    "        - finish performance_dash function\n",
    "        - finish send_alerts function\n",
    "        - finish logging function\n",
    "\n",
    "Improvements\n",
    "    \n",
    "    - calculate more features for modeling\n",
    "    - grid search and shapley for feature engineering\n",
    "    - Test different classification models\n",
    "    - optimize for bucket thresholds \n",
    "    -\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Pre-Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get exchange assets and Trading Pairs from Shrimpy API\n",
    "def get_base_exchange_data(exchange):\n",
    "    # Get Digital Asset Data\n",
    "    def get_exchange_assets(exchange):\n",
    "        exchange_assets = shrimpy_client.get_exchange_assets(exchange)\n",
    "        exchange_assets_df = pd.DataFrame(columns=['id','name', 'symbol', 'trading_symbol'])\n",
    "        for key, value in enumerate(exchange_assets):\n",
    "            exchange_assets_df.loc[key] = [value['id'], value['name'], value['symbol'], value['tradingSymbol']]\n",
    "        return exchange_assets_df\n",
    "\n",
    "    def calc_trading_pairs_df(exchange):\n",
    "        exchange_pairs = shrimpy_client.get_trading_pairs(exchange)\n",
    "        exchange_pairs_df = pd.DataFrame(columns=['base','quote'])\n",
    "        for key, value in enumerate(exchange_pairs):\n",
    "            exchange_pairs_df.loc[key] = [value['baseTradingSymbol'],value['quoteTradingSymbol']]\n",
    "        return exchange_pairs_df\n",
    "    return get_exchange_assets(exchange), calc_trading_pairs_df(exchange)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and organize closing prices into datafram for one ticker from shrimpy rest api\n",
    "def get_prices_df(candles):\n",
    "    time = []\n",
    "    prices = []\n",
    "    for key, value in enumerate(candles):\n",
    "        time.append(value['time'])\n",
    "        prices.append(value['close'])\n",
    "    prices_df = pd.DataFrame(list(zip(time, prices)), columns = ['time', 'close'])\n",
    "    prices_df['time'] = pd.to_datetime(prices_df['time'])\n",
    "    prices_df['close'] = pd.to_numeric(prices_df['close'])\n",
    "    prices_df.set_index('time', inplace=True)\n",
    "    return prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and organize closing prices into dataframe from list of trading pairs from one exchange from shrimpy rest api\n",
    "def get_prices(exchange, trading_pairs_df, interval, start):\n",
    "    master_prices_df = pd.DataFrame()\n",
    "    for index, row in trading_pairs_df.iterrows():\n",
    "        candles = shrimpy_client.get_candles(exchange, row['base'], row['quote'], interval, start)\n",
    "        time = []\n",
    "        prices = []\n",
    "        for key, value in enumerate(candles):\n",
    "            time.append(value['time'])\n",
    "            prices.append(value['close'])\n",
    "        prices_df = pd.DataFrame(list(zip(time, prices)), columns = ['time', row['base'] + \"_\" + row['quote']])\n",
    "        prices_df['time'] = pd.to_datetime(prices_df['time'])\n",
    "        if master_prices_df.empty:\n",
    "            master_prices_df = prices_df\n",
    "        else:\n",
    "            master_prices_df = pd.merge(master_prices_df, prices_df, left_on='time', right_on = 'time', how = 'left')\n",
    "    return master_prices_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Engineering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure rows are every 6hrs, if there is no row-then make one and forward fill data (shrimpy doesn't print candle if there is no tick)\n",
    "def calc_feature_dataframe(prices_df):\n",
    "    ## cumulative returns as velocity\n",
    "    ## Log returns as velocity\n",
    "    ## partials?\n",
    "    ## Lags?\n",
    "    ## Technical Indicators\n",
    "    ## Social Indicators\n",
    "    df_features = prices_df\n",
    "    # Construct dependent variable\n",
    "    df_features['returns'] = df_features['close'].pct_change()\n",
    "    # Calculate cumulative returns\n",
    "    df_features['cum_returns'] = (df_features['returns']+1).cumprod()\n",
    "    # ----------------------- Price Dynamics --------------------------------\n",
    "    # price dynamics as a one Dimensional particle problem in physics\n",
    "    df_features['price_velocity_2'] = df_features['close'].pct_change(2)\n",
    "    df_features['price_velocity_3'] = df_features['close'].pct_change(3)\n",
    "    df_features['price_velocity_4'] = df_features['close'].pct_change(4)\n",
    "    df_features['price_velocity_7'] = df_features['close'].pct_change(7)\n",
    "    df_features['price_velocity_30'] = df_features['close'].pct_change(30)\n",
    "    \n",
    "    df_features['price_acceleration_1'] = df_features['returns'].pct_change(1)\n",
    "    df_features['price_acceleration_2'] = df_features['price_velocity_2'].pct_change(2)\n",
    "    df_features['price_acceleration_3'] = df_features['price_velocity_3'].pct_change(3)\n",
    "    df_features['price_acceleration_4'] = df_features['price_velocity_4'].pct_change(4)\n",
    "    df_features['price_acceleration_7'] = df_features['price_velocity_7'].pct_change(7)\n",
    "    df_features['price_acceleration_30'] = df_features['price_velocity_30'].pct_change(30)\n",
    "\n",
    "    df_features['rolling_mean_velocity_2'] = df_features['returns'].rolling(window=2).mean()\n",
    "    df_features['rolling_mean_velocity_3'] = df_features['returns'].rolling(window=3).mean()\n",
    "    df_features['rolling_mean_velocity_4'] = df_features['returns'].rolling(window=4).mean()\n",
    "    df_features['rolling_mean_velocity_7'] = df_features['returns'].rolling(window=7).mean()\n",
    "    df_features['rolling_mean_velocity_30'] = df_features['returns'].rolling(window=30).mean()\n",
    "    \n",
    "    df_features['rolling_mean_acceleration_2'] = df_features['price_acceleration_1'].rolling(window=2).mean()\n",
    "    df_features['rolling_mean_acceleration_3'] = df_features['price_acceleration_1'].rolling(window=3).mean()\n",
    "    df_features['rolling_mean_acceleration_4'] = df_features['price_acceleration_1'].rolling(window=4).mean()\n",
    "    df_features['rolling_mean_acceleration_7'] = df_features['price_acceleration_1'].rolling(window=7).mean()\n",
    "    df_features['rolling_mean_acceleration_30'] = df_features['price_acceleration_1'].rolling(window=30).mean()\n",
    "    # To extend space to entire line the log price is mapped to position x(t) in the space by\n",
    "    # x(t) = log(S(t))   where S(t) is the price of the instrument\n",
    "    df_features['log_price'] = np.log(df_features['close'])\n",
    "    df_features['log_returns'] = df_features['log_price'].diff() # Diff or percent change\n",
    "    #df_features['log_return_pct']  = df_features['log_price'].pct()\n",
    "    #df_features['cum_log_returns'] =(df_features['log_returns_pct'] + 1).cumprod()\n",
    "    # Assumption: Returns of financial instruments are lognormally distributed\n",
    "    # v(t) = R(t) = dx(t)/dt where v(t) is the velocity of the instrument in the log price space, x(t)\n",
    "    \n",
    "    # ------------------------------ partial price dynamics ---------------------\n",
    "    # -------------------------------Technical Indicators ------------------------\n",
    "    df_features.dropna(inplace=True)\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. XG Boost Multi-Classification Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "### Not finished\n",
    "def xg_boost_multiclassifier(df):\n",
    "    #bin_labels_5_name = ['very_bear', 'bear', 'neutral', 'bull', 'very_bull']\n",
    "    bin_labels_5 = ['1', '2', '3', '4', '5']\n",
    "    class_df = df.copy()\n",
    "    class_df['return_class'] = pd.cut(df_features.returns,\n",
    "                                  bins=[-np.inf, -.02,-.0025, .0025, .02, np.inf], labels=bin_labels_5)\n",
    "    class_df.dropna(inplace=True)\n",
    "    # Need to clean up numbers for model\n",
    "    cleanup_nums = {\"return_class\": {\"1\": round(1), \"2\": round(2), \"3\": round(3), \"4\": round(4), \"5\": round(5)}}\n",
    "    class_df.replace(cleanup_nums, inplace=True)\n",
    "    # X,y Test/Train Split for ML Classification Models\n",
    "    X = class_df.copy()\n",
    "    X.drop([\"close\", \"returns\", \"return_class\"], axis=1, inplace=True)\n",
    "    y = class_df[\"return_class\"].values.reshape(-1, 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "    # Train Model\n",
    "    model = xgb.XGBClassifier(objective='multi:softmax', num_class=5).fit(X_train,y_train)\n",
    "    # Test model\n",
    "    predictions = model.predict(X_test)\n",
    "    predicted_returns = predictions.reshape(-1,1)\n",
    "    real_returns = y_test.reshape(-1, 1)\n",
    "    # Create dataframe with columns real returns, predicted returns, and accuracy\n",
    "    predicted_returns_xgb = pd.DataFrame({\n",
    "        \"Real\": real_returns.ravel(),\n",
    "        \"y_test\": y_test.ravel(),\n",
    "        \"Predicted\": predicted_returns.ravel()\n",
    "    })\n",
    "    return predicted_returns_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- need to make sure timestamps are on predicted dataframe for backtest\n",
    "- need to train sequentially\n",
    "- save model using joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Backtesting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_analysis(test_df, initial_capital, exchange, rebalance_freq, start, end, fee_perc, tax_fee):\n",
    "    name_of_model = 'XGB Multi-Classifier'\n",
    "    initial_capital = float(initial_capital)\n",
    "    # BTC-USD Trend thresholds\n",
    "    very_bullish = 5 # if btc price prediction is greater than \n",
    "    bullish = 4 # if btc\n",
    "    nuetral = 3 # if btc is predicting 0 returns\n",
    "    bearish = 2 # if btc is predicting negative returns\n",
    "    very_bearish = 1 # if btci predicting very negative returns\n",
    "    # Set Threshold Weights (create global variables as input...)\n",
    "    # ***** figure out how to train a model to predict class ranges for trend thresholds\n",
    "    # ***** figure out how to train a model to predict best allocation wts given the class prediction\n",
    "    btc_wts = [.2,.4,.5,.5,.4]\n",
    "    usd_wts = [.8,.6,.4,.2, 0]\n",
    "    alt_wts = [0,0,.1,.3,.6]\n",
    "    # Create balance lists to populate when looping through dataframe\n",
    "    bucket_1_position = []\n",
    "    bucket_2_position = []\n",
    "    bucket_3_position = []\n",
    "    usd_balance = []\n",
    "    btc_balance = []\n",
    "    time = []\n",
    "    for index, row in test_df.iterrows():\n",
    "        # Strategy Logic    \n",
    "        if row['predicted_class'] == 5: # Very Bull\n",
    "            bucket_1_position.append(usd_wts[4])\n",
    "            bucket_2_position.append(btc_wts[4])\n",
    "            bucket_3_position.append(alt_wts[4])\n",
    "            balance_usd = row['']* usd_wts[4]\n",
    "            balance_btc = row['']\n",
    "            \n",
    "            time.append(row['time'])\n",
    "        elif row['predicted_class'] == 4: # Bull\n",
    "            bucket_1_position.append(usd_wts[3])\n",
    "            bucket_2_position.append(btc_wts[3])\n",
    "            bucket_3_position.append(alt_wts[3])\n",
    "            time.append(row['time'])          \n",
    "        elif row['predicted_class'] == 3: # Neutral\n",
    "            bucket_1_position.append(usd_wts[2])\n",
    "            bucket_2_position.append(btc_wts[2])\n",
    "            bucket_3_position.append(alt_wts[2])\n",
    "            time.append(row['time'])\n",
    "        elif row['predicted_class'] == 2: # Bear\n",
    "            bucket_1_position.append(usd_wts[1])\n",
    "            bucket_2_position.append(btc_wts[1])\n",
    "            bucket_3_position.append(alt_wts[1])\n",
    "            time.append(row['time'])\n",
    "        elif row['predicted_class'] == 1: # Very Bear\n",
    "            bucket_1_position.append(usd_wts[0])\n",
    "            bucket_2_position.append(btc_wts[0])\n",
    "            bucket_3_position.append(alt_wts[0])\n",
    "            time.append(row['time'])\n",
    "\n",
    "    # Create positions dataframe  \n",
    "    positions_df = pd.DataFrame(list(zip(time, bucket_1_position, bucket_2_position, bucket_3_position)),\n",
    "                                 columns =['time', 'bucket_1_position', 'bucket_2_position', 'bucket_3_position'])   \n",
    "    \n",
    "    # Merge positions dataframe with backtest dataframe\n",
    "    final_backtest_df = pd.merge(test_df, positions_df, how='left', on='time')\n",
    "    # Market Dynamics Columns\n",
    "    final_backtest_df['btc_price_change'] = backtest_df['btc_price'].pct_change()\n",
    "    final_backtest_df['eth_price_change'] = backtest_df['ethbtc_price'].pct_change()\n",
    "    # Portfolio Columns\n",
    "    final_backtest_df['portfolio_balance_usd'] = final_backtest_df['bucket_1_position'] \n",
    "    final_backtest_df['portfolio_returns_usd'] =  final\n",
    "    final_backtest_df['portfolio_cum_returns_usd'] = \n",
    "    final_backtest_df['portfolio_balance_btc'] = \n",
    "    final_backtest_df['portfolio_returns_btc'] =\n",
    "    final_backtest_df['portfolio_cum_returns_btc'] =\n",
    "    # Position Columns\n",
    "    final_backtest_df['bucket_1_position_change'] = backtest_df['bucket_1_position'].diff()\n",
    "    final_backtest_df['bucket_2_position_change'] = backtest_df['bucket_2_position'].diff()\n",
    "    final_backtest_df['bucket_3_position_change'] = backtest_df['bucket_3_position'].diff()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ---------------------------------- Calc Portfolio Performance ------------------------\n",
    "    \n",
    "    #backtest_results_df1['alpha'] = backtest_results_df1['usd_cum_returns'] - backtest_results_df1['btcusd_cum_returns']\n",
    "    #backtest_results_df1['usd_rolling_returns_wk'] = backtest_results_df1['usd_perc_change'].rolling(7).sum()\n",
    "    #backtest_results_df1['btc_rolling_returns_wk'] = backtest_results_df1['btc_perc_change'].rolling(7).sum()\n",
    "    #backtest_results_df1['usd_rolling_vol_wk'] = backtest_results_df1['usd_perc_change'].rolling(7).std()\n",
    "    #backtest_results_df1['btc_rolling_vol_wk'] = backtest_results_df1['btc_perc_change'].rolling(7).std()\n",
    "    #backtest_results_df1['usd_rolling_returns_mo'] = backtest_results_df1['usd_perc_change'].rolling(7).sum()\n",
    "    #backtest_results_df1['btc_rolling_returns_mo'] = backtest_results_df1['btc_perc_change'].rolling(7).sum()\n",
    "    #backtest_results_df1['usd_rolling_vol_mo'] = backtest_results_df1['usd_perc_change'].rolling(30).std()\n",
    "    #backtest_results_df1['btc_rolling_vol_mo'] = backtest_results_df1['btc_perc_change'].rolling(30).std()\n",
    "    #\n",
    "    #backtest_results_df1['usd_rolling_sharpe_wk'] = backtest_results_df1['usd_rolling_returns_wk']/backtest_results_df1['usd_rolling_vol_wk']\n",
    "    #backtest_results_df1['btc_rolling_sharpe_wk'] = backtest_results_df1['btc_rolling_returns_wk']/backtest_results_df1['btc_rolling_vol_wk']\n",
    "    #backtest_results_df1['usd_rolling_sharpe_mo'] = backtest_results_df1['usd_rolling_returns_mo']/backtest_results_df1['usd_rolling_vol_mo']\n",
    "    #backtest_results_df1['btc_rolling_sharpe_mo'] = backtest_results_df1['btc_rolling_returns_mo']/backtest_results_df1['btc_rolling_vol_mo']\n",
    "    \n",
    "    # More Risk Measures\n",
    "        # Max Drawdown \n",
    "        # Skewness\n",
    "        # Kurtosis\n",
    "        # VAR\n",
    "        # CVAR\n",
    "        # Time under water   \n",
    "    usd_metrics= [\n",
    "        'initial_capital',\n",
    "        'cumulative_returns',\n",
    "        'annualized_returns',\n",
    "        'mthly_returns',\n",
    "        'annual_vol',\n",
    "        'mthly_vol',\n",
    "        'annual_sharpe',\n",
    "        'mthly_sharpe',\n",
    "        'annual_sortino',\n",
    "        'mthly_sortino',\n",
    "    ]\n",
    "    \n",
    "    btc_metrics = [\n",
    "        \n",
    "        'initial_capital',\n",
    "        'cumulative_returns',\n",
    "        'annualized_returns',\n",
    "        'mthly_returns',\n",
    "        'annual_vol',\n",
    "        'mthly_vol',\n",
    "        'annual_sharpe',\n",
    "        'mthly_sharpe',\n",
    "        'annual_sortino',\n",
    "        'mthly_sortino',\n",
    "    ]\n",
    "    \n",
    "    columns = ['Backtest']\n",
    "    \n",
    "    port_eval_df_usd = pd.DataFrame(index=usd_metrics, columns=columns)\n",
    "    \n",
    "    port_eval_df_usd.loc['initial_capital'] = initial_capital\n",
    "    port_eval_df_usd.loc['cumulative_returns'] = final_backtest_df['portfolio_cum_returns_usd'].iloc[-1]\n",
    "    port_eval_df_usd.loc['annualized_returns'] = final_backtest_df['portfolio_returns_usd'].mean() *365  #Crypto trades 365 days per year\n",
    "    port_eval_df_usd.loc['mthly_returns'] = final_backtest_df['portfolio_returns_usd'].mean() *30\n",
    "    port_eval_df_usd.loc['annual_vol'] = final_backtest_df['portfolio_returns_usd'].std() * np.sqrt(365)  #Crypto trades 365 days per year\n",
    "    port_eval_df_usd.loc['mthly_vol'] = final_backtest_df['portfolio_returns_usd'].std() * np.sqrt(30)\n",
    "    port_eval_df_usd.loc['annual_sharpe'] = port_eval_df_usd.loc['annualized_returns']/port_eval_df_usd.loc['annual_vol']\n",
    "    port_eval_df_usd.loc['mthly_sharpe'] = port_eval_df_usd.loc['mthly_returns']/port_eval_df_usd.loc['mthly_vol']\n",
    "        \n",
    "    \n",
    "    port_eval_df_btc = pd.DataFrame(index=btc_metrics, columns=columns)\n",
    "    port_eval_df_btc.loc['initial_capital'] = final_backtest_df['portfolio_balance_btc'].iloc[0]\n",
    "    port_eval_df_btc.loc['cumulative_returns'] = final_backtest_df['portfolio_cum_returns_btc'].iloc[-1]\n",
    "    port_eval_df_btc.loc['annualized_returns'] = final_backtest_df['portfolio_returns_btc'].mean() *365  #Crypto trades 365 days per year\n",
    "    port_eval_df_btc.loc['mthly_returns'] = final_backtest_df['portfolio_returns_btc'].mean() *30\n",
    "    port_eval_df_btc.loc['annual_vol'] = final_backtest_df['portfolio_returns_btc'].mean() * np.sqrt(365) #Crypto trades 365 days per year\n",
    "    port_eval_df_btc.loc['mthly_vol'] = final_backtest_df['portfolio_returns_btc'].mean() * np.sqrt(30)\n",
    "    port_eval_df_btc.loc['annual_sharpe'] = port_eval_df_btc.loc['annualized_returns']/port_eval_df_btc.loc['annual_vol']\n",
    "    port_eval_df_btc.loc['mthly_sharpe'] = port_eval_df_btc.loc['mthly_returns']/port_eval_df_btc.loc['mthly_vol']\n",
    "    \n",
    "    # Calculate Sortino Ratios\n",
    "    sortino_ratio_df = final_backtest_df[['portfolio_returns_usd','portfolio_returns_btc']].copy()\n",
    "    sortino_ratio_df.loc[:, \"downside_usd\"] = 0\n",
    "    sortino_ratio_df.loc[:,\"downside_btc\"] = 0\n",
    "    target = 0\n",
    "    mask_usd = sortino_ratio_df['portfolio_returns_usd'] < target\n",
    "    mask_btc = sortino_ratio_df['portfolio_returns_btc'] < target\n",
    "    \n",
    "    sortino_ratio_df.loc[mask_usd, \"portfolio_returns_usd\"] = (sortino_ratio_df[\"portfolio_returns_usd\"]**2)\n",
    "    sortino_ratio_df.loc[mask_btc, \"portfolio_returns_btc\"] = (sortino_ratio_df[\"portfolio_returns_btc\"]**2)\n",
    "    \n",
    "    down_stdev_usd_annual = np.sqrt(sortino_ratio_df['downside_usd'].mean()) * np.sqrt(365)\n",
    "    down_stdev_btc_annual = np.sqrt(sortino_ratio_df['downside_btc'].mean()) * np.sqrt(365)\n",
    "    down_stdev_btc_mthly = np.sqrt(sortino_ratio_df['downside_btc'].mean()) * np.sqrt(30)\n",
    "    down_stdev_usd_mthly = np.sqrt(sortino_ratio_df['downside_usd'].mean()) * np.sqrt(30)\n",
    "    \n",
    "    expected_return_usd_annual = sortino_ratio_df['portfolio_returns_usd'].mean()*365\n",
    "    expected_return_btc_annual = sortino_ratio_df['portfolio_returns_btc'].mean()*365\n",
    "    sortino_ratio_usd_annual = expected_return_usd_annual/down_stdev_usd_annual\n",
    "    sortino_ratio_btc_annual = expected_return_btc_annual/down_stdev_btc_annual\n",
    "    \n",
    "    expected_return_usd_mthly = sortino_ratio_df['portfolio_returns_usd'].mean()*30\n",
    "    expected_return_btc_mthly = sortino_ratio_df['portfolio_returns_btc'].mean()*30\n",
    "    \n",
    "    sortino_ratio_usd_mthly = expected_return_usd_mthly/down_stdev_usd_mthly\n",
    "    sortino_ratio_btc_mthly = expected_return_btc_mthly/down_stdev_btc_mthly\n",
    "    \n",
    "    port_eval_df_usd.loc['annual_sortino'] = sortino_ratio_usd_annual\n",
    "    port_eval_df_usd.loc['mthly_sortino'] = sortino_ratio_usd_mthly\n",
    "    port_eval_df_btc.loc['annual_sortino'] = sortino_ratio_btc_annual\n",
    "    port_eval_df_btc.loc['mthly_sortino'] = sortino_ratio_usd_mthly\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # --------------------------------------------- print Performance stats ------------------------------------------\n",
    "    # Print out Performance Tables\n",
    "    print(port_eval_df_usd)\n",
    "    print(port_eval_df_btc)\n",
    "    \n",
    "    # Risk Visualizations    \n",
    "    #final_backtest_df['rolling_sharpe'] !!!! NEED TO MAKE SURE THERE IS A ROW EVERY 6 HOURS\n",
    "    final_backtest_df[['portfolio_returns_usd', 'portfolio_returns_btc']]\n",
    "    # Reward Measures\n",
    "    final_backtest_df['portfolio_cum_returns_usd'].plot()\n",
    "    final_backtest_df['portfolio_cum_returns_btc'].plot()  \n",
    "    final_backtest_df['portfolio_returns_usd'].plot()\n",
    "    final_backtest_df['portfolio_returns_btc'].plot()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Tasks\n",
    "- need test_df function to come in sequentially\n",
    "- make sure test dataframe has rows that print every 6 hours ... note that shrimpy doesn't print candle if there is no tick. Do this in \n",
    "- finish strategy logic (update balances as we iterate through rows)\n",
    "\n",
    "- check for balance calcs, time calc, and kpi calc errors\n",
    "- return print out format like metin's return function\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Portfolio Backtest Performance Dashboard Model\n",
    "    1. Input Variables\n",
    "    2. Run Backtest\n",
    "    3. Evaluate Static Performance Statistics\n",
    "        - performance measured in usd\n",
    "        - performance measured in btc\n",
    "    4. Visualize Risk Adjusted Performance over time\n",
    "        - Reward\n",
    "            - Daily Returns\n",
    "            - Cumulative Returns\n",
    "            - Rolling Returns\n",
    "            - Alpha\n",
    "        - Risk\n",
    "            - box plots\n",
    "            - rolling vol\n",
    "            - rolling sharpe\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Live Trade Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- LIVE TRADING ----------------------------------------------\n",
    "# --- copyright- (MANTIS TRADING, LLP // Mantis Copyright Token // open source // ) \n",
    "# --- mantistrading.win\n",
    "# --- version \"0.01\"\n",
    "# --- live_trader_mantis.py\n",
    "# -----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def initialize():\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# --------------- Initialize the dashboard, data storage, and account balances --------------\n",
    "# -------------------------------------------------------------------------------------------\n",
    "    print(\"Intializing Account and DataFrame\")\n",
    "    df = fetch_data()\n",
    "    # DEFINE User ID\n",
    "    shrimpy_users = client.list_users()\n",
    "    shrimpy_user_id = users[0]['id'] # Could go crazy if we can write a scaling function here...multiplied with an AWS RoboAdivsor or app\n",
    "    # Initialize Account\n",
    "    account = {\"balance\": , \"\": 0}\n",
    "    df = fetch_data()\n",
    "    return account, df\n",
    "\n",
    "def fetch_data():\n",
    "    # Set environment variables from the .env file\n",
    "    env_path = Path(\"/Users/gdepa\")/'grant_api_keys.env'\n",
    "    load_dotenv(env_path)\n",
    "    shrimpy_public_key = os.getenv(\"SHRIMPY_PUBLIC_KEY\")\n",
    "    shrimpy_private_key = os.getenv(\"SHRIMPY_PRIVATE_KEY\")\n",
    "\n",
    "    shrimpy_client = shrimpy.ShrimpyApiClient(shrimpy_public_key, shrimpy_private_key)\n",
    "    ## Retrieve price information from shrimpy websocket\n",
    "    \n",
    "    return prices_df\n",
    "\n",
    "def generate_features(prices_df):\n",
    "    ## Calcluate Feature Datframe from prices df\n",
    "    return features_df\n",
    "    \n",
    "    \n",
    "def rebalancePortfolio(features_df, account_id, user_id):\n",
    "    # \n",
    "    return account\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### May not need\n",
    "async def main():\n",
    "    loop = asyncio.get_event_loop()\n",
    "    while True:\n",
    "        global account\n",
    "        global prices_df\n",
    "        # global dashboard\n",
    "        \n",
    "        new_df = await loop.run_in_executor(Non, fetch_data)\n",
    "        df = df.append(new_df, ignore_index=True)\n",
    "        \n",
    "        min_window = 22\n",
    "        if df.shape[0]>= min_window:\n",
    "            features = generate_features(prices_df)\n",
    "            account = rebalancePortfolio(features, account)\n",
    "            \n",
    "        # update_dashboard(prices_df, dashboard)\n",
    "        await asyncio.sleep(1)\n",
    "        \n",
    "# Python 3.7+\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Real-Time Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- REAL-TIME MANAGER ---------------------------------\n",
    "# --- copyright- (MANTIS TRADING, LLP // Mantis Copyright Token // open source // )\n",
    "# --- mantistrading.win *\n",
    "# --- version \"0.01\"\n",
    "# --- real_time_manager.py\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------- POPULATE Performance Dash -------------------------------\n",
    "# Global Stats\n",
    "    # Total Account Value\n",
    "    # Capital at Risk: [BTC, %], [USD, %]  * exposure outside base currency\n",
    "    # Expected Accumulation: [ BTC, % ], [USD,%]\n",
    "    # Current Accuumulation: [ BTC, % ], [USD,%]\n",
    "\n",
    "# Visualizations\n",
    "    # (Multi and single account) Timeseries Options\n",
    "        # BTC Accumulation relative to expected return\n",
    "        # Bucket Allocation Weights relative to thresholds\n",
    "        # ALT Asset Allocation weights relative to thresholds\n",
    " \n",
    "    # (Multi and single account) Pie charts Options\n",
    "        # Bucket Allocation weights relative to thresholds\n",
    "        # ALT Asset Allocation weights relative to thresholds\n",
    "\n",
    "    # (Multi and Single account) Radial\n",
    "        # btc accumulation rate\n",
    "        # bucket accumulation rates\n",
    "        # ALT Asset Accumulation rates\n",
    "    \n",
    "# ------------------------------ Send Alerts --------------------------------------\n",
    "# Send Performance Report every 6hrs\n",
    "# Send Alert on RISKS Thresholds- [High negative accumulation_rate, max_drawdown, VAR, etc..]\n",
    "# Send Alert on WINS-[High positive accumulation_rate]\n",
    "# Send Alert on KILL SWITCH\n",
    "\n",
    "\n",
    "# ---------------------------- Log Essential Data ----------------------------------\n",
    "# 1. Save Trades DF to database\n",
    "# 2. Save orders DF to database\n",
    "# 3. Save capital_gains df to database\n",
    "# 4. Save KPIs dataframe to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
